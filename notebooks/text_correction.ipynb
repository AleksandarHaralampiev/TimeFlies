{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Correction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if i am using the gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.test import is_gpu_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Vasil\\AppData\\Local\\Temp\\ipykernel_10608\\4182541057.py:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vasil\\anaconda3\\envs\\tech_stack\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"jhu-clsp/jfleg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'corrections'],\n",
       "        num_rows: 755\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'corrections'],\n",
       "        num_rows: 748\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.DataFrame(dataset['validation'])\n",
    "test_df = pd.DataFrame(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>corrections</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So I think we can not live if old people could...</td>\n",
       "      <td>[So I think we would not be alive if our ances...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For not use car .</td>\n",
       "      <td>[Not for use with a car . , Do not use in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Here was no promise of morning except that we ...</td>\n",
       "      <td>[Here was no promise of morning , except that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thus even today sex is considered as the least...</td>\n",
       "      <td>[Thus , even today , sex is considered as the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image you salf you are wark in factory just to...</td>\n",
       "      <td>[Imagine yourself you are working in factory j...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  So I think we can not live if old people could...   \n",
       "1                                 For not use car .    \n",
       "2  Here was no promise of morning except that we ...   \n",
       "3  Thus even today sex is considered as the least...   \n",
       "4  image you salf you are wark in factory just to...   \n",
       "\n",
       "                                         corrections  \n",
       "0  [So I think we would not be alive if our ances...  \n",
       "1  [Not for use with a car . , Do not use in the ...  \n",
       "2  [Here was no promise of morning , except that ...  \n",
       "3  [Thus , even today , sex is considered as the ...  \n",
       "4  [Imagine yourself you are working in factory j...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence       So I think we can not live if old people could...\n",
       "corrections    [So I think we would not be alive if our ances...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrap = train_df.iloc[0]\n",
    "wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  So I think we can not live if old people could not find siences and tecnologies and they did not developped . \n",
      "Corrections:\n",
      "So I think we would not be alive if our ancestors did not develop sciences and technologies . \n",
      "So I think we could not live if older people did not develop science and technologies . \n",
      "So I think we can not live if old people could not find science and technologies and they did not develop . \n",
      "So I think we can not live if old people can not find the science and technology that has not been developed . \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vasil\\AppData\\Local\\Temp\\ipykernel_10608\\1885658631.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(f\"Sentence: \", wrap[0])\n",
      "C:\\Users\\Vasil\\AppData\\Local\\Temp\\ipykernel_10608\\1885658631.py:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  for i in wrap[1]:\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sentence: \", wrap[0])\n",
    "print(f\"Corrections:\")\n",
    "for i in wrap[1]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>corrections</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So I think we can not live if old people could...</td>\n",
       "      <td>[So I think we would not be alive if our ances...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For not use car .</td>\n",
       "      <td>[Not for use with a car . , Do not use in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Here was no promise of morning except that we ...</td>\n",
       "      <td>[Here was no promise of morning , except that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thus even today sex is considered as the least...</td>\n",
       "      <td>[Thus , even today , sex is considered as the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image you salf you are wark in factory just to...</td>\n",
       "      <td>[Imagine yourself you are working in factory j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>The government also should try to reduce the s...</td>\n",
       "      <td>[The government should also try to reduce the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>Alot of memories with enogh time to remember w...</td>\n",
       "      <td>[A lot of memories , with enough time to remem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>Sceene of violence can affect on them .</td>\n",
       "      <td>[A scene of violence can have an effect on the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>While the communities in general have reckoned...</td>\n",
       "      <td>[The communities in general have reckoned that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td></td>\n",
       "      <td>[, , , ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>755 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  \\\n",
       "0    So I think we can not live if old people could...   \n",
       "1                                   For not use car .    \n",
       "2    Here was no promise of morning except that we ...   \n",
       "3    Thus even today sex is considered as the least...   \n",
       "4    image you salf you are wark in factory just to...   \n",
       "..                                                 ...   \n",
       "750  The government also should try to reduce the s...   \n",
       "751  Alot of memories with enogh time to remember w...   \n",
       "752           Sceene of violence can affect on them .    \n",
       "753  While the communities in general have reckoned...   \n",
       "754                                                      \n",
       "\n",
       "                                           corrections  \n",
       "0    [So I think we would not be alive if our ances...  \n",
       "1    [Not for use with a car . , Do not use in the ...  \n",
       "2    [Here was no promise of morning , except that ...  \n",
       "3    [Thus , even today , sex is considered as the ...  \n",
       "4    [Imagine yourself you are working in factory j...  \n",
       "..                                                 ...  \n",
       "750  [The government should also try to reduce the ...  \n",
       "751  [A lot of memories , with enough time to remem...  \n",
       "752  [A scene of violence can have an effect on the...  \n",
       "753  [The communities in general have reckoned that...  \n",
       "754                                           [, , , ]  \n",
       "\n",
       "[755 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['text'] = [' '.join([sentence, *corrections]) for sentence, corrections in zip(train_df['sentence'], train_df['corrections'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>corrections</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So I think we can not live if old people could...</td>\n",
       "      <td>[So I think we would not be alive if our ances...</td>\n",
       "      <td>So I think we can not live if old people could...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For not use car .</td>\n",
       "      <td>[Not for use with a car . , Do not use in the ...</td>\n",
       "      <td>For not use car .  Not for use with a car .  D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Here was no promise of morning except that we ...</td>\n",
       "      <td>[Here was no promise of morning , except that ...</td>\n",
       "      <td>Here was no promise of morning except that we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thus even today sex is considered as the least...</td>\n",
       "      <td>[Thus , even today , sex is considered as the ...</td>\n",
       "      <td>Thus even today sex is considered as the least...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image you salf you are wark in factory just to...</td>\n",
       "      <td>[Imagine yourself you are working in factory j...</td>\n",
       "      <td>image you salf you are wark in factory just to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>The government also should try to reduce the s...</td>\n",
       "      <td>[The government should also try to reduce the ...</td>\n",
       "      <td>The government also should try to reduce the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>Alot of memories with enogh time to remember w...</td>\n",
       "      <td>[A lot of memories , with enough time to remem...</td>\n",
       "      <td>Alot of memories with enogh time to remember w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>Sceene of violence can affect on them .</td>\n",
       "      <td>[A scene of violence can have an effect on the...</td>\n",
       "      <td>Sceene of violence can affect on them .  A sce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>While the communities in general have reckoned...</td>\n",
       "      <td>[The communities in general have reckoned that...</td>\n",
       "      <td>While the communities in general have reckoned...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td></td>\n",
       "      <td>[, , , ]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>755 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  \\\n",
       "0    So I think we can not live if old people could...   \n",
       "1                                   For not use car .    \n",
       "2    Here was no promise of morning except that we ...   \n",
       "3    Thus even today sex is considered as the least...   \n",
       "4    image you salf you are wark in factory just to...   \n",
       "..                                                 ...   \n",
       "750  The government also should try to reduce the s...   \n",
       "751  Alot of memories with enogh time to remember w...   \n",
       "752           Sceene of violence can affect on them .    \n",
       "753  While the communities in general have reckoned...   \n",
       "754                                                      \n",
       "\n",
       "                                           corrections  \\\n",
       "0    [So I think we would not be alive if our ances...   \n",
       "1    [Not for use with a car . , Do not use in the ...   \n",
       "2    [Here was no promise of morning , except that ...   \n",
       "3    [Thus , even today , sex is considered as the ...   \n",
       "4    [Imagine yourself you are working in factory j...   \n",
       "..                                                 ...   \n",
       "750  [The government should also try to reduce the ...   \n",
       "751  [A lot of memories , with enough time to remem...   \n",
       "752  [A scene of violence can have an effect on the...   \n",
       "753  [The communities in general have reckoned that...   \n",
       "754                                           [, , , ]   \n",
       "\n",
       "                                                  text  \n",
       "0    So I think we can not live if old people could...  \n",
       "1    For not use car .  Not for use with a car .  D...  \n",
       "2    Here was no promise of morning except that we ...  \n",
       "3    Thus even today sex is considered as the least...  \n",
       "4    image you salf you are wark in factory just to...  \n",
       "..                                                 ...  \n",
       "750  The government also should try to reduce the s...  \n",
       "751  Alot of memories with enogh time to remember w...  \n",
       "752  Sceene of violence can affect on them .  A sce...  \n",
       "753  While the communities in general have reckoned...  \n",
       "754                                                     \n",
       "\n",
       "[755 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'So I think we can not live if old people could not find siences and tecnologies and they did not developped .  So I think we would not be alive if our ancestors did not develop sciences and technologies .  So I think we could not live if older people did not develop science and technologies .  So I think we can not live if old people could not find science and technologies and they did not develop .  So I think we can not live if old people can not find the science and technology that has not been developed . '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrap = train_df.iloc[0]\n",
    "wrap['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "411"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = train_df['sentence'].str.len().max()\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "vocab_size = 25000\n",
    "seq_len = 500\n",
    "\n",
    "text_vectorizer = TextVectorization(\n",
    "    max_tokens = vocab_size,\n",
    "    output_mode = 'int',\n",
    "    output_sequence_length = seq_len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer.adapt(train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wrap = test_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(500,), dtype=int64, numpy=\n",
       "array([  67,    4,   67,  422,   61,  143, 1502,    3,    2,  172,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0], dtype=int64)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorizer(test_wrap['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(wrap['corrections']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4): \n",
    "    train_df[f'correction_{i+1}'] = train_df['corrections'].apply(lambda x: x[i] if i < len(x) else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>corrections</th>\n",
       "      <th>text</th>\n",
       "      <th>correction_1</th>\n",
       "      <th>correction_2</th>\n",
       "      <th>correction_3</th>\n",
       "      <th>correction_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So I think we can not live if old people could...</td>\n",
       "      <td>[So I think we would not be alive if our ances...</td>\n",
       "      <td>So I think we can not live if old people could...</td>\n",
       "      <td>So I think we would not be alive if our ancest...</td>\n",
       "      <td>So I think we could not live if older people d...</td>\n",
       "      <td>So I think we can not live if old people could...</td>\n",
       "      <td>So I think we can not live if old people can n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For not use car .</td>\n",
       "      <td>[Not for use with a car . , Do not use in the ...</td>\n",
       "      <td>For not use car .  Not for use with a car .  D...</td>\n",
       "      <td>Not for use with a car .</td>\n",
       "      <td>Do not use in the car .</td>\n",
       "      <td>Car not for use .</td>\n",
       "      <td>Can not use the car .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Here was no promise of morning except that we ...</td>\n",
       "      <td>[Here was no promise of morning , except that ...</td>\n",
       "      <td>Here was no promise of morning except that we ...</td>\n",
       "      <td>Here was no promise of morning , except that w...</td>\n",
       "      <td>Here , there was no promise of morning , excep...</td>\n",
       "      <td>Here was no promise of morning except that we ...</td>\n",
       "      <td>There was no promise of morning except when we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thus even today sex is considered as the least...</td>\n",
       "      <td>[Thus , even today , sex is considered as the ...</td>\n",
       "      <td>Thus even today sex is considered as the least...</td>\n",
       "      <td>Thus , even today , sex is considered as the l...</td>\n",
       "      <td>Thus , even today , sex is considered the leas...</td>\n",
       "      <td>Thus , even today , sex is considered the leas...</td>\n",
       "      <td>Thus , even today sex is considered as the lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image you salf you are wark in factory just to...</td>\n",
       "      <td>[Imagine yourself you are working in factory j...</td>\n",
       "      <td>image you salf you are wark in factory just to...</td>\n",
       "      <td>Imagine yourself you are working in factory ju...</td>\n",
       "      <td>Imagine that you work in a factory and do just...</td>\n",
       "      <td>image you salf you are wark in factory just to...</td>\n",
       "      <td>Imagine yourself working in a factory. You are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>The government also should try to reduce the s...</td>\n",
       "      <td>[The government should also try to reduce the ...</td>\n",
       "      <td>The government also should try to reduce the s...</td>\n",
       "      <td>The government should also try to reduce the s...</td>\n",
       "      <td>The government should also try to reduce the s...</td>\n",
       "      <td>The government should also try to reduce the s...</td>\n",
       "      <td>The government should also try to reduce the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>Alot of memories with enogh time to remember w...</td>\n",
       "      <td>[A lot of memories , with enough time to remem...</td>\n",
       "      <td>Alot of memories with enogh time to remember w...</td>\n",
       "      <td>A lot of memories , with enough time to rememb...</td>\n",
       "      <td>Many memories with enough time to remember wil...</td>\n",
       "      <td>A lot of memories , with enough time to rememb...</td>\n",
       "      <td>A lot of memories with enough time to remember...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>Sceene of violence can affect on them .</td>\n",
       "      <td>[A scene of violence can have an effect on the...</td>\n",
       "      <td>Sceene of violence can affect on them .  A sce...</td>\n",
       "      <td>A scene of violence can have an effect on them .</td>\n",
       "      <td>Scenes of violence can have an affect on them .</td>\n",
       "      <td>Scenes of violence can have an effect on them .</td>\n",
       "      <td>Scenes of violence can affect them .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>While the communities in general have reckoned...</td>\n",
       "      <td>[The communities in general have reckoned that...</td>\n",
       "      <td>While the communities in general have reckoned...</td>\n",
       "      <td>The communities in general have reckoned that ...</td>\n",
       "      <td>While the communities in general have reckoned...</td>\n",
       "      <td>While the communities in general have recogniz...</td>\n",
       "      <td>While the communities in general believe that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td></td>\n",
       "      <td>[, , , ]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>755 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  \\\n",
       "0    So I think we can not live if old people could...   \n",
       "1                                   For not use car .    \n",
       "2    Here was no promise of morning except that we ...   \n",
       "3    Thus even today sex is considered as the least...   \n",
       "4    image you salf you are wark in factory just to...   \n",
       "..                                                 ...   \n",
       "750  The government also should try to reduce the s...   \n",
       "751  Alot of memories with enogh time to remember w...   \n",
       "752           Sceene of violence can affect on them .    \n",
       "753  While the communities in general have reckoned...   \n",
       "754                                                      \n",
       "\n",
       "                                           corrections  \\\n",
       "0    [So I think we would not be alive if our ances...   \n",
       "1    [Not for use with a car . , Do not use in the ...   \n",
       "2    [Here was no promise of morning , except that ...   \n",
       "3    [Thus , even today , sex is considered as the ...   \n",
       "4    [Imagine yourself you are working in factory j...   \n",
       "..                                                 ...   \n",
       "750  [The government should also try to reduce the ...   \n",
       "751  [A lot of memories , with enough time to remem...   \n",
       "752  [A scene of violence can have an effect on the...   \n",
       "753  [The communities in general have reckoned that...   \n",
       "754                                           [, , , ]   \n",
       "\n",
       "                                                  text  \\\n",
       "0    So I think we can not live if old people could...   \n",
       "1    For not use car .  Not for use with a car .  D...   \n",
       "2    Here was no promise of morning except that we ...   \n",
       "3    Thus even today sex is considered as the least...   \n",
       "4    image you salf you are wark in factory just to...   \n",
       "..                                                 ...   \n",
       "750  The government also should try to reduce the s...   \n",
       "751  Alot of memories with enogh time to remember w...   \n",
       "752  Sceene of violence can affect on them .  A sce...   \n",
       "753  While the communities in general have reckoned...   \n",
       "754                                                      \n",
       "\n",
       "                                          correction_1  \\\n",
       "0    So I think we would not be alive if our ancest...   \n",
       "1                            Not for use with a car .    \n",
       "2    Here was no promise of morning , except that w...   \n",
       "3    Thus , even today , sex is considered as the l...   \n",
       "4    Imagine yourself you are working in factory ju...   \n",
       "..                                                 ...   \n",
       "750  The government should also try to reduce the s...   \n",
       "751  A lot of memories , with enough time to rememb...   \n",
       "752  A scene of violence can have an effect on them .    \n",
       "753  The communities in general have reckoned that ...   \n",
       "754                                                      \n",
       "\n",
       "                                          correction_2  \\\n",
       "0    So I think we could not live if older people d...   \n",
       "1                             Do not use in the car .    \n",
       "2    Here , there was no promise of morning , excep...   \n",
       "3    Thus , even today , sex is considered the leas...   \n",
       "4    Imagine that you work in a factory and do just...   \n",
       "..                                                 ...   \n",
       "750  The government should also try to reduce the s...   \n",
       "751  Many memories with enough time to remember wil...   \n",
       "752   Scenes of violence can have an affect on them .    \n",
       "753  While the communities in general have reckoned...   \n",
       "754                                                      \n",
       "\n",
       "                                          correction_3  \\\n",
       "0    So I think we can not live if old people could...   \n",
       "1                                   Car not for use .    \n",
       "2    Here was no promise of morning except that we ...   \n",
       "3    Thus , even today , sex is considered the leas...   \n",
       "4    image you salf you are wark in factory just to...   \n",
       "..                                                 ...   \n",
       "750  The government should also try to reduce the s...   \n",
       "751  A lot of memories , with enough time to rememb...   \n",
       "752   Scenes of violence can have an effect on them .    \n",
       "753  While the communities in general have recogniz...   \n",
       "754                                                      \n",
       "\n",
       "                                          correction_4  \n",
       "0    So I think we can not live if old people can n...  \n",
       "1                               Can not use the car .   \n",
       "2    There was no promise of morning except when we...  \n",
       "3    Thus , even today sex is considered as the lea...  \n",
       "4    Imagine yourself working in a factory. You are...  \n",
       "..                                                 ...  \n",
       "750  The government should also try to reduce the s...  \n",
       "751  A lot of memories with enough time to remember...  \n",
       "752              Scenes of violence can affect them .   \n",
       "753  While the communities in general believe that ...  \n",
       "754                                                     \n",
       "\n",
       "[755 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: For one correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3167"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_sequences(train_df['sentence'])\n",
    "y_train = tokenizer.texts_to_sequences(train_df['correction_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33,\n",
       " 10,\n",
       " 57,\n",
       " 23,\n",
       " 22,\n",
       " 19,\n",
       " 119,\n",
       " 28,\n",
       " 111,\n",
       " 15,\n",
       " 100,\n",
       " 19,\n",
       " 151,\n",
       " 2427,\n",
       " 3,\n",
       " 2428,\n",
       " 3,\n",
       " 11,\n",
       " 228,\n",
       " 19,\n",
       " 2429]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max(max(len(seq) for seq in X_train), max(len(seq) for seq in y_train))\n",
    "X_train = pad_sequences(X_train, maxlen=max_length, padding='post')\n",
    "y_train = pad_sequences(y_train, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  33,   10,   57,   23,   22,   19,  119,   28,  111,   15,  100,\n",
       "         19,  151, 2427,    3, 2428,    3,   11,  228,   19, 2429,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, GRU, Dense, Embedding, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow import clip_by_value\n",
    "\n",
    "inputs = Input(shape=(max_length,), dtype='int32')\n",
    "x = Embedding(vocab_size, 256)(inputs)\n",
    "x = GRU(128, return_sequences=True)(x)\n",
    "x = Dense(vocab_size, activation = 'softmax')(x)  \n",
    "model = Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 76)]              0         \n",
      "                                                                 \n",
      " embedding_11 (Embedding)    (None, 76, 256)           810752    \n",
      "                                                                 \n",
      " gru_21 (GRU)                (None, 76, 128)           148224    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 76, 3167)          408543    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,367,519\n",
      "Trainable params: 1,367,519\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.4173 - accuracy: 0.7864\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.4005 - accuracy: 0.7876\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.3839 - accuracy: 0.7880\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.3682 - accuracy: 0.7881\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.3552 - accuracy: 0.7881\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.3438 - accuracy: 0.7883\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.3331 - accuracy: 0.7883\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.3229 - accuracy: 0.7883\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.3125 - accuracy: 0.7885\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.3014 - accuracy: 0.7892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e7921fd420>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 82ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the a                                                                          '"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sentence = \"Hello, is everything alright?\"\n",
    "new_sequence = tokenizer.texts_to_sequences([new_sentence])\n",
    "padded_sequence = pad_sequences(new_sequence, maxlen=max_length, padding='post')\n",
    "predictions = model.predict(padded_sequence)\n",
    "predicted_sentence = []\n",
    "for timestep in predictions[0]:\n",
    "    predicted_word_index = np.argmax(timestep)\n",
    "    predicted_word = tokenizer.index_word.get(predicted_word_index, \"\")\n",
    "    predicted_sentence.append(predicted_word)\n",
    "\n",
    "# Join the predicted words to form the corrected sentence\n",
    "corrected_sentence = \" \".join(predicted_sentence)\n",
    "\n",
    "corrected_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
